{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üè• Medical Model Optimization + Mixture of Experts  \n",
        "## ‚öôÔ∏è Notebook 3: Experts Benchmarks\n",
        "\n",
        "**Authors:**  \n",
        "- Dan Harvey  \n",
        "- Xinzhuo Jiang  \n",
        "\n",
        "**Affiliation:**  \n",
        "*High-Performance Machine Learning (HPML)*  \n",
        "*Columbia University*\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### üîç Project Overview\n",
        "\n",
        "In this section, we evaluate how quantization affects model load time, memory usage, and inference speed.\n",
        "\n",
        "\n",
        "### üéØ Objectives\n",
        "\n",
        "- Load `Llama-3-8B-UltraMedical` in FP16, 8-bit, and 4-bit quantized formats\n",
        "- Time each loading operation\n",
        "- Profile memory usage using `nvidia-smi`\n",
        "- Compare load time, memory, and performance tradeoffs\n",
        "\n",
        "We use Hugging Face‚Äôs quantization options and BitsAndBytes for INT8/INT4 support."
      ],
      "metadata": {
        "id": "bOYNbu9h-YfD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzQBSM2l-JxM",
        "outputId": "43ad86f9-e7f3-4013-c41c-3027c8216f5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "## üì¶ Environment Setup: Dependencies and Imports\n",
        "\n",
        "import torch\n",
        "import time\n",
        "import os\n",
        "import subprocess\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers import BitsAndBytesConfig\n",
        "import gc\n",
        "import sys\n",
        "import importlib\n",
        "!pip install -U bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add project root to path\n",
        "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
        "if project_root not in sys.path:\n",
        "    sys.path.append(project_root)\n",
        "\n",
        "# Required packages\n",
        "required_packages = [\n",
        "    'torch', 'transformers', 'datasets', 'accelerate', 'flash_attn',\n",
        "    'evaluate', 'lm_eval', 'sklearn', 'matplotlib', 'wandb',\n",
        "    'tqdm', 'sentencepiece', 'scipy', 'einops'\n",
        "]\n",
        "\n",
        "# Check and install missing packages\n",
        "for package in required_packages:\n",
        "    try:\n",
        "        module = importlib.import_module(package)\n",
        "        print(f\"‚úÖ {package} installed successfully\")\n",
        "        if package == 'torch':\n",
        "            print(f\"   Version: {torch.__version__}\")\n",
        "            print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
        "            if torch.cuda.is_available():\n",
        "                print(f\"   CUDA version: {torch.version.cuda}\")\n",
        "                print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        elif hasattr(module, '__version__'):\n",
        "            print(f\"   Version: {module.__version__}\")\n",
        "    except ImportError:\n",
        "        print(f\"‚ùå {package} not found. Installing...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "        module = importlib.import_module(package)\n",
        "        print(f\"‚úÖ {package} installed successfully (post-install)\")\n",
        "        if hasattr(module, '__version__'):\n",
        "            print(f\"   Version: {module.__version__}\")\n",
        "\n",
        "# You may need to restart the Kernel to use these"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUT-gzYOA1d1",
        "outputId": "e5cb99d0-a13a-4ec3-f7c0-bd855cc48379"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ torch installed successfully\n",
            "   Version: 2.6.0+cu124\n",
            "   CUDA available: True\n",
            "   CUDA version: 12.4\n",
            "   GPU: NVIDIA A100-SXM4-40GB\n",
            "‚úÖ transformers installed successfully\n",
            "   Version: 4.51.3\n",
            "‚úÖ datasets installed successfully\n",
            "   Version: 3.6.0\n",
            "‚úÖ accelerate installed successfully\n",
            "   Version: 1.6.0\n",
            "‚úÖ flash_attn installed successfully\n",
            "   Version: 2.7.4.post1\n",
            "‚úÖ evaluate installed successfully\n",
            "   Version: 0.4.3\n",
            "‚úÖ lm_eval installed successfully\n",
            "‚úÖ sklearn installed successfully\n",
            "   Version: 1.6.1\n",
            "‚úÖ matplotlib installed successfully\n",
            "   Version: 3.10.0\n",
            "‚úÖ wandb installed successfully\n",
            "   Version: 0.19.10\n",
            "‚úÖ tqdm installed successfully\n",
            "   Version: 4.67.1\n",
            "‚úÖ sentencepiece installed successfully\n",
            "   Version: 0.2.0\n",
            "‚úÖ scipy installed successfully\n",
            "   Version: 1.15.2\n",
            "‚úÖ einops installed successfully\n",
            "   Version: 0.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount drive to get the experts models\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLOcE70ylI6o",
        "outputId": "41f5063b-dc02-4825-b2e0-d6fec0289dad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load section dependencies\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "import gc"
      ],
      "metadata": {
        "id": "NlkZyAs5CTF4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîê Hugging Face Access - Llama is Gated\n",
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg89e1hCCcVH",
        "outputId": "7d8b87eb-ba27-4e1e-b796-aae60076aac8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `hpml_token` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `hpml_token`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import section dependencies\n",
        "import platform\n",
        "import psutil\n",
        "import distro\n",
        "import numpy as np\n",
        "\n",
        "# ==========================\n",
        "# üñ•Ô∏è System & OS Information\n",
        "# ==========================\n",
        "system_info = platform.uname()\n",
        "\n",
        "print(\"üñ•Ô∏è System Information\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"Node Name      : {system_info.node}\")\n",
        "print(f\"System         : {platform.system()}\")\n",
        "print(f\"OS Flavor      : {distro.name()}\")\n",
        "print(f\"OS Version     : {distro.version()}\")\n",
        "print(f\"Release        : {system_info.release}\")\n",
        "print(f\"Architecture   : {platform.machine()}\")\n",
        "print(f\"Python Version : {platform.python_version()}\")\n",
        "\n",
        "# =====================\n",
        "# üß† CPU Information\n",
        "# =====================\n",
        "cpu_count = psutil.cpu_count(logical=False)\n",
        "logical_cpu_count = psutil.cpu_count(logical=True)\n",
        "\n",
        "print(\"\\nüß† CPU Information\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"Processor      : {system_info.processor or platform.processor()}\")\n",
        "print(f\"Physical Cores : {cpu_count}\")\n",
        "print(f\"Logical Cores  : {logical_cpu_count}\")\n",
        "\n",
        "# ======================\n",
        "# üß† Memory Information\n",
        "# ======================\n",
        "memory_info = psutil.virtual_memory()\n",
        "\n",
        "print(\"\\nüß† Memory Information\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"Total RAM      : {memory_info.total / 1024 ** 3:.2f} GB\")\n",
        "print(f\"Available RAM  : {memory_info.available / 1024 ** 3:.2f} GB\")\n",
        "print(f\"Used RAM       : {memory_info.used / 1024 ** 3:.2f} GB\")\n",
        "\n",
        "# =======================\n",
        "# üíæ Disk Information\n",
        "# =======================\n",
        "disk_info = psutil.disk_usage('/')\n",
        "\n",
        "print(\"\\nüíæ Disk Information\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"Total Space    : {disk_info.total / 1024 ** 3:.2f} GB\")\n",
        "print(f\"Used Space     : {disk_info.used / 1024 ** 3:.2f} GB\")\n",
        "print(f\"Free Space     : {disk_info.free / 1024 ** 3:.2f} GB\")\n",
        "\n",
        "# =======================\n",
        "# üß† GPU Information\n",
        "# =======================\n",
        "\n",
        "print(\"\\nüß† GPU Info\")\n",
        "print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "print(\"CUDA Available:\", True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_S9JpaMEVLP",
        "outputId": "1130517b-6b9a-48ee-a6c5-c92c1ff87e80"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üñ•Ô∏è System Information\n",
            "----------------------------------------\n",
            "Node Name      : d5718e995c35\n",
            "System         : Linux\n",
            "OS Flavor      : Ubuntu\n",
            "OS Version     : 22.04\n",
            "Release        : 6.1.123+\n",
            "Architecture   : x86_64\n",
            "Python Version : 3.11.12\n",
            "\n",
            "üß† CPU Information\n",
            "----------------------------------------\n",
            "Processor      : x86_64\n",
            "Physical Cores : 6\n",
            "Logical Cores  : 12\n",
            "\n",
            "üß† Memory Information\n",
            "----------------------------------------\n",
            "Total RAM      : 83.48 GB\n",
            "Available RAM  : 80.37 GB\n",
            "Used RAM       : 2.24 GB\n",
            "\n",
            "üíæ Disk Information\n",
            "----------------------------------------\n",
            "Total Space    : 235.68 GB\n",
            "Used Space     : 87.98 GB\n",
            "Free Space     : 147.68 GB\n",
            "\n",
            "üß† GPU Info\n",
            "GPU: NVIDIA A100-SXM4-40GB\n",
            "CUDA Available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ü¶ô Llama-3-8B-UltraMedical MoE\n",
        "\n",
        "**Experts**\n",
        "- Cardiology Expert: ü§ó [Hugging Face Model Card](https://huggingface.co/xj2193/medmoe-cardiology-expert)\n",
        "- Orthopedic Expert: ü§ó [Hugging Face Model Card](https://huggingface.co/xj2193/medmoe-orthopedic-expert)\n",
        "- Mental Health Expert: ü§ó [Hugging Face Model Card](https://huggingface.co/xj2193/medmoe-mentalhealth-expert)\n",
        "\n",
        "These experts are quantized in 4bit precision.\n"
      ],
      "metadata": {
        "id": "yROwGNat-7oi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ü¶ô Cardiology Expert Benchmarks"
      ],
      "metadata": {
        "id": "QH35_sR8_dZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Benchmark Cardiology Expert\n",
        "import random\n",
        "import json\n",
        "import wandb\n",
        "import subprocess\n",
        "import time\n",
        "import os\n",
        "from datetime import datetime\n",
        "import lm_eval\n",
        "\n",
        "# -----------------------------\n",
        "# üß† Model and Task Config\n",
        "# -----------------------------\n",
        "\n",
        "model_name = \"TsinghuaC3I/Llama-3-8B-UltraMedical\"\n",
        "peft_model_name = \"xj2193/medmoe-cardiology-expert\"\n",
        "task_name = \"pubmedqa\"\n",
        "output_base = \"./results\"\n",
        "\n",
        "# -----------------------------\n",
        "# üöÄ Start W&B run\n",
        "# -----------------------------\n",
        "run_name = f\"{model_name.replace('/', '_')}_{task_name}_cardiology_expert_5x\"\n",
        "wandb_run = wandb.init(\n",
        "    project=\"med-moe-baseline-evals\",\n",
        "    name=run_name,\n",
        "    config={\n",
        "        \"model\": model_name,\n",
        "        \"task\": task_name,\n",
        "        \"batch_size\": 8,\n",
        "        \"precision\": \"fp16\",\n",
        "        \"eval_method\": \"lm_eval\",\n",
        "        \"repeats\": 5\n",
        "    }\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# üîÅ Run 5x Evaluation Loop\n",
        "# -----------------------------\n",
        "for i in range(5):\n",
        "    print(f\"\\nüîÅ Run {i + 1}/5\")\n",
        "\n",
        "    # Create timestamped output folder\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
        "    day = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    run_output_dir = os.path.join(output_base, f\"run_{i+1}_{timestamp}\")\n",
        "    os.makedirs(run_output_dir, exist_ok=True)\n",
        "\n",
        "    # Define lm_eval command\n",
        "    command = [\n",
        "        \"lm_eval\",\n",
        "        \"--model\", \"hf\",\n",
        "        \"--tasks\", task_name,\n",
        "        \"--model_args\", f\"pretrained={model_name},peft=xj2193/medmoe-cardiology-expert,load_in_4bit=True,parallelize=True,device_map=auto,llm_int8_enable_fp32_cpu_offload=True\",\n",
        "        \"--device\", \"cuda:0\",\n",
        "        \"--batch_size\", \"8\",\n",
        "        \"--write_out\",\n",
        "        \"--output_path\", run_output_dir,\n",
        "        \"--trust_remote_code\",\n",
        "        \"--confirm_run_unsafe_code\"\n",
        "    ]\n",
        "\n",
        "    # Start timing\n",
        "    start_time = time.monotonic()\n",
        "    result = subprocess.run(command, capture_output=True, text=True)\n",
        "    elapsed = time.monotonic() - start_time\n",
        "\n",
        "    print(f\"‚úÖ Run {i + 1} completed in {elapsed:.2f} seconds\")\n",
        "    print(\"STDOUT:\\n\", result.stdout)\n",
        "\n",
        "    # -----------------------------\n",
        "    # üìä Find and parse result file\n",
        "    # -----------------------------\n",
        "    result_file = None\n",
        "    for fname in os.listdir(os.path.join(run_output_dir, peft_model_name.replace('/', '__'))):\n",
        "        print(fname)\n",
        "        if fname.startswith(f\"results_{day}\") and fname.endswith(\".json\"):\n",
        "            result_file = os.path.join(run_output_dir, peft_model_name.replace('/', '__'), fname)\n",
        "            with open(result_file, 'r') as f:\n",
        "                result = json.load(f)\n",
        "                acc = result['results'][task_name]['acc,none']\n",
        "                stderr = result['results'][task_name]['acc_stderr,none']\n",
        "\n",
        "                wandb_run.log({f\"{task_name}/eval_time_sec\": elapsed,\n",
        "                              f\"{task_name}/accuracy\": acc,\n",
        "                              f\"{task_name}/stderr\": stderr,\n",
        "                              \"run_index\": i + 1\n",
        "                              })\n",
        "                print(f\"üìà Logged to W&B: acc={acc:.3f}, stderr={stderr:.4f}\")\n",
        "\n",
        "    if result_file is None:\n",
        "        print(f\"‚ùå No eval_results_*.json found in {run_output_dir}\")\n",
        "        continue\n",
        "\n",
        "# -----------------------------\n",
        "# ‚úÖ Finish W&B run\n",
        "# -----------------------------\n",
        "wandb_run.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eHlDd_wAFP78",
        "outputId": "bfb509ee-05b7-4524-cf81-92ab866e51f8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">TsinghuaC3I_Llama-3-8B-UltraMedical_pubmedqa_cardiology_expert_5x</strong> at: <a href='https://wandb.ai/med-moe/med-moe-baseline-evals/runs/p5vxmd1d' target=\"_blank\">https://wandb.ai/med-moe/med-moe-baseline-evals/runs/p5vxmd1d</a><br> View project at: <a href='https://wandb.ai/med-moe/med-moe-baseline-evals' target=\"_blank\">https://wandb.ai/med-moe/med-moe-baseline-evals</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250508_215423-p5vxmd1d/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250508_215623-ytfkeivu</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/med-moe/med-moe-baseline-evals/runs/ytfkeivu' target=\"_blank\">TsinghuaC3I_Llama-3-8B-UltraMedical_pubmedqa_cardiology_expert_5x</a></strong> to <a href='https://wandb.ai/med-moe/med-moe-baseline-evals' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/med-moe/med-moe-baseline-evals' target=\"_blank\">https://wandb.ai/med-moe/med-moe-baseline-evals</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/med-moe/med-moe-baseline-evals/runs/ytfkeivu' target=\"_blank\">https://wandb.ai/med-moe/med-moe-baseline-evals/runs/ytfkeivu</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîÅ Run 1/5\n",
            "‚úÖ Run 1 completed in 70.41 seconds\n",
            "STDOUT:\n",
            " hf (pretrained=TsinghuaC3I/Llama-3-8B-UltraMedical,peft=xj2193/medmoe-cardiology-expert,load_in_4bit=True,parallelize=True,device_map=auto,llm_int8_enable_fp32_cpu_offload=True,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "| Tasks  |Version|Filter|n-shot|Metric|   |Value|   |Stderr|\n",
            "|--------|------:|------|-----:|------|---|----:|---|-----:|\n",
            "|pubmedqa|      1|none  |     0|acc   |‚Üë  |0.672|¬±  | 0.021|\n",
            "\n",
            "\n",
            "results_2025-05-08T21-57-33.765988.json\n",
            "üìà Logged to W&B: acc=0.672, stderr=0.0210\n",
            "\n",
            "üîÅ Run 2/5\n",
            "‚úÖ Run 2 completed in 70.28 seconds\n",
            "STDOUT:\n",
            " hf (pretrained=TsinghuaC3I/Llama-3-8B-UltraMedical,peft=xj2193/medmoe-cardiology-expert,load_in_4bit=True,parallelize=True,device_map=auto,llm_int8_enable_fp32_cpu_offload=True,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "| Tasks  |Version|Filter|n-shot|Metric|   |Value|   |Stderr|\n",
            "|--------|------:|------|-----:|------|---|----:|---|-----:|\n",
            "|pubmedqa|      1|none  |     0|acc   |‚Üë  |0.672|¬±  | 0.021|\n",
            "\n",
            "\n",
            "results_2025-05-08T21-58-44.006715.json\n",
            "üìà Logged to W&B: acc=0.672, stderr=0.0210\n",
            "\n",
            "üîÅ Run 3/5\n",
            "‚úÖ Run 3 completed in 70.23 seconds\n",
            "STDOUT:\n",
            " hf (pretrained=TsinghuaC3I/Llama-3-8B-UltraMedical,peft=xj2193/medmoe-cardiology-expert,load_in_4bit=True,parallelize=True,device_map=auto,llm_int8_enable_fp32_cpu_offload=True,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "| Tasks  |Version|Filter|n-shot|Metric|   |Value|   |Stderr|\n",
            "|--------|------:|------|-----:|------|---|----:|---|-----:|\n",
            "|pubmedqa|      1|none  |     0|acc   |‚Üë  |0.672|¬±  | 0.021|\n",
            "\n",
            "\n",
            "results_2025-05-08T21-59-54.274803.json\n",
            "üìà Logged to W&B: acc=0.672, stderr=0.0210\n",
            "\n",
            "üîÅ Run 4/5\n",
            "‚úÖ Run 4 completed in 69.66 seconds\n",
            "STDOUT:\n",
            " hf (pretrained=TsinghuaC3I/Llama-3-8B-UltraMedical,peft=xj2193/medmoe-cardiology-expert,load_in_4bit=True,parallelize=True,device_map=auto,llm_int8_enable_fp32_cpu_offload=True,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "| Tasks  |Version|Filter|n-shot|Metric|   |Value|   |Stderr|\n",
            "|--------|------:|------|-----:|------|---|----:|---|-----:|\n",
            "|pubmedqa|      1|none  |     0|acc   |‚Üë  |0.672|¬±  | 0.021|\n",
            "\n",
            "\n",
            "results_2025-05-08T22-01-03.909907.json\n",
            "üìà Logged to W&B: acc=0.672, stderr=0.0210\n",
            "\n",
            "üîÅ Run 5/5\n",
            "‚úÖ Run 5 completed in 70.50 seconds\n",
            "STDOUT:\n",
            " hf (pretrained=TsinghuaC3I/Llama-3-8B-UltraMedical,peft=xj2193/medmoe-cardiology-expert,load_in_4bit=True,parallelize=True,device_map=auto,llm_int8_enable_fp32_cpu_offload=True,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "| Tasks  |Version|Filter|n-shot|Metric|   |Value|   |Stderr|\n",
            "|--------|------:|------|-----:|------|---|----:|---|-----:|\n",
            "|pubmedqa|      1|none  |     0|acc   |‚Üë  |0.672|¬±  | 0.021|\n",
            "\n",
            "\n",
            "results_2025-05-08T22-02-14.342064.json\n",
            "üìà Logged to W&B: acc=0.672, stderr=0.0210\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pubmedqa/accuracy</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>pubmedqa/eval_time_sec</td><td>‚ñá‚ñÜ‚ñÜ‚ñÅ‚ñà</td></tr><tr><td>pubmedqa/stderr</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>run_index</td><td>‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pubmedqa/accuracy</td><td>0.672</td></tr><tr><td>pubmedqa/eval_time_sec</td><td>70.49784</td></tr><tr><td>pubmedqa/stderr</td><td>0.02102</td></tr><tr><td>run_index</td><td>5</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">TsinghuaC3I_Llama-3-8B-UltraMedical_pubmedqa_cardiology_expert_5x</strong> at: <a href='https://wandb.ai/med-moe/med-moe-baseline-evals/runs/ytfkeivu' target=\"_blank\">https://wandb.ai/med-moe/med-moe-baseline-evals/runs/ytfkeivu</a><br> View project at: <a href='https://wandb.ai/med-moe/med-moe-baseline-evals' target=\"_blank\">https://wandb.ai/med-moe/med-moe-baseline-evals</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250508_215623-ytfkeivu/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Benchmark Orthopedic Expert\n",
        "import random\n",
        "import json\n",
        "import wandb\n",
        "import subprocess\n",
        "import time\n",
        "import os\n",
        "from datetime import datetime\n",
        "import lm_eval\n",
        "\n",
        "# -----------------------------\n",
        "# üß† Model and Task Config\n",
        "# -----------------------------\n",
        "\n",
        "model_name = \"TsinghuaC3I/Llama-3-8B-UltraMedical\"\n",
        "peft_model_name = \"xj2193/medmoe-orthopedic-expert\"\n",
        "task_name = \"pubmedqa\"\n",
        "output_base = \"./results\"\n",
        "\n",
        "# -----------------------------\n",
        "# üöÄ Start W&B run\n",
        "# -----------------------------\n",
        "run_name = f\"{model_name.replace('/', '_')}_{task_name}_orthopedic_expert_5x\"\n",
        "wandb_run = wandb.init(\n",
        "    project=\"med-moe-baseline-evals\",\n",
        "    name=run_name,\n",
        "    config={\n",
        "        \"model\": model_name,\n",
        "        \"task\": task_name,\n",
        "        \"batch_size\": 8,\n",
        "        \"precision\": \"fp16\",\n",
        "        \"eval_method\": \"lm_eval\",\n",
        "        \"repeats\": 5\n",
        "    }\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# üîÅ Run 5x Evaluation Loop\n",
        "# -----------------------------\n",
        "for i in range(5):\n",
        "    print(f\"\\nüîÅ Run {i + 1}/5\")\n",
        "\n",
        "    # Create timestamped output folder\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
        "    day = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    run_output_dir = os.path.join(output_base, f\"run_{i+1}_{timestamp}\")\n",
        "    os.makedirs(run_output_dir, exist_ok=True)\n",
        "\n",
        "    # Define lm_eval command\n",
        "    command = [\n",
        "        \"lm_eval\",\n",
        "        \"--model\", \"hf\",\n",
        "        \"--tasks\", task_name,\n",
        "        \"--model_args\", f\"pretrained={model_name},peft=xj2193/medmoe-orthopedic-expert,load_in_4bit=True,parallelize=True,device_map=auto,llm_int8_enable_fp32_cpu_offload=True\",\n",
        "        \"--device\", \"cuda:0\",\n",
        "        \"--batch_size\", \"8\",\n",
        "        \"--write_out\",\n",
        "        \"--output_path\", run_output_dir,\n",
        "        \"--trust_remote_code\",\n",
        "        \"--confirm_run_unsafe_code\"\n",
        "    ]\n",
        "\n",
        "    # Start timing\n",
        "    start_time = time.monotonic()\n",
        "    result = subprocess.run(command, capture_output=True, text=True)\n",
        "    elapsed = time.monotonic() - start_time\n",
        "\n",
        "    print(f\"‚úÖ Run {i + 1} completed in {elapsed:.2f} seconds\")\n",
        "    print(\"STDOUT:\\n\", result.stdout)\n",
        "\n",
        "    # -----------------------------\n",
        "    # üìä Find and parse result file\n",
        "    # -----------------------------\n",
        "    result_file = None\n",
        "    for fname in os.listdir(os.path.join(run_output_dir, peft_model_name.replace('/', '__'))):\n",
        "        print(fname)\n",
        "        if fname.startswith(f\"results_{day}\") and fname.endswith(\".json\"):\n",
        "            result_file = os.path.join(run_output_dir, peft_model_name.replace('/', '__'), fname)\n",
        "            with open(result_file, 'r') as f:\n",
        "                result = json.load(f)\n",
        "                acc = result['results'][task_name]['acc,none']\n",
        "                stderr = result['results'][task_name]['acc_stderr,none']\n",
        "\n",
        "                wandb_run.log({f\"{task_name}/eval_time_sec\": elapsed,\n",
        "                              f\"{task_name}/accuracy\": acc,\n",
        "                              f\"{task_name}/stderr\": stderr,\n",
        "                              \"run_index\": i + 1\n",
        "                              })\n",
        "                print(f\"üìà Logged to W&B: acc={acc:.3f}, stderr={stderr:.4f}\")\n",
        "\n",
        "    if result_file is None:\n",
        "        print(f\"‚ùå No eval_results_*.json found in {run_output_dir}\")\n",
        "        continue\n",
        "\n",
        "# -----------------------------\n",
        "# ‚úÖ Finish W&B run\n",
        "# -----------------------------\n",
        "wandb_run.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4m7ZCehJ60xY",
        "outputId": "0ea88f93-026f-43fd-a098-8837a1d43a0a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250508_220251-hrkxqzhy</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/med-moe/med-moe-baseline-evals/runs/hrkxqzhy' target=\"_blank\">TsinghuaC3I_Llama-3-8B-UltraMedical_pubmedqa_orthopedic_expert_5x</a></strong> to <a href='https://wandb.ai/med-moe/med-moe-baseline-evals' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/med-moe/med-moe-baseline-evals' target=\"_blank\">https://wandb.ai/med-moe/med-moe-baseline-evals</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/med-moe/med-moe-baseline-evals/runs/hrkxqzhy' target=\"_blank\">https://wandb.ai/med-moe/med-moe-baseline-evals/runs/hrkxqzhy</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîÅ Run 1/5\n",
            "‚úÖ Run 1 completed in 71.10 seconds\n",
            "STDOUT:\n",
            " hf (pretrained=TsinghuaC3I/Llama-3-8B-UltraMedical,peft=xj2193/medmoe-orthopedic-expert,load_in_4bit=True,parallelize=True,device_map=auto,llm_int8_enable_fp32_cpu_offload=True,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "| Tasks  |Version|Filter|n-shot|Metric|   |Value|   |Stderr|\n",
            "|--------|------:|------|-----:|------|---|----:|---|-----:|\n",
            "|pubmedqa|      1|none  |     0|acc   |‚Üë  |0.776|¬±  |0.0187|\n",
            "\n",
            "\n",
            "results_2025-05-08T22-04-01.675250.json\n",
            "üìà Logged to W&B: acc=0.776, stderr=0.0187\n",
            "\n",
            "üîÅ Run 2/5\n",
            "‚úÖ Run 2 completed in 70.78 seconds\n",
            "STDOUT:\n",
            " hf (pretrained=TsinghuaC3I/Llama-3-8B-UltraMedical,peft=xj2193/medmoe-orthopedic-expert,load_in_4bit=True,parallelize=True,device_map=auto,llm_int8_enable_fp32_cpu_offload=True,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "| Tasks  |Version|Filter|n-shot|Metric|   |Value|   |Stderr|\n",
            "|--------|------:|------|-----:|------|---|----:|---|-----:|\n",
            "|pubmedqa|      1|none  |     0|acc   |‚Üë  |0.776|¬±  |0.0187|\n",
            "\n",
            "\n",
            "results_2025-05-08T22-05-12.517641.json\n",
            "üìà Logged to W&B: acc=0.776, stderr=0.0187\n",
            "\n",
            "üîÅ Run 3/5\n",
            "‚úÖ Run 3 completed in 70.78 seconds\n",
            "STDOUT:\n",
            " hf (pretrained=TsinghuaC3I/Llama-3-8B-UltraMedical,peft=xj2193/medmoe-orthopedic-expert,load_in_4bit=True,parallelize=True,device_map=auto,llm_int8_enable_fp32_cpu_offload=True,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "| Tasks  |Version|Filter|n-shot|Metric|   |Value|   |Stderr|\n",
            "|--------|------:|------|-----:|------|---|----:|---|-----:|\n",
            "|pubmedqa|      1|none  |     0|acc   |‚Üë  |0.776|¬±  |0.0187|\n",
            "\n",
            "\n",
            "results_2025-05-08T22-06-23.341650.json\n",
            "üìà Logged to W&B: acc=0.776, stderr=0.0187\n",
            "\n",
            "üîÅ Run 4/5\n",
            "‚úÖ Run 4 completed in 70.19 seconds\n",
            "STDOUT:\n",
            " hf (pretrained=TsinghuaC3I/Llama-3-8B-UltraMedical,peft=xj2193/medmoe-orthopedic-expert,load_in_4bit=True,parallelize=True,device_map=auto,llm_int8_enable_fp32_cpu_offload=True,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "| Tasks  |Version|Filter|n-shot|Metric|   |Value|   |Stderr|\n",
            "|--------|------:|------|-----:|------|---|----:|---|-----:|\n",
            "|pubmedqa|      1|none  |     0|acc   |‚Üë  |0.776|¬±  |0.0187|\n",
            "\n",
            "\n",
            "results_2025-05-08T22-07-33.481151.json\n",
            "üìà Logged to W&B: acc=0.776, stderr=0.0187\n",
            "\n",
            "üîÅ Run 5/5\n",
            "‚úÖ Run 5 completed in 70.70 seconds\n",
            "STDOUT:\n",
            " hf (pretrained=TsinghuaC3I/Llama-3-8B-UltraMedical,peft=xj2193/medmoe-orthopedic-expert,load_in_4bit=True,parallelize=True,device_map=auto,llm_int8_enable_fp32_cpu_offload=True,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "| Tasks  |Version|Filter|n-shot|Metric|   |Value|   |Stderr|\n",
            "|--------|------:|------|-----:|------|---|----:|---|-----:|\n",
            "|pubmedqa|      1|none  |     0|acc   |‚Üë  |0.776|¬±  |0.0187|\n",
            "\n",
            "\n",
            "results_2025-05-08T22-08-44.171109.json\n",
            "üìà Logged to W&B: acc=0.776, stderr=0.0187\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pubmedqa/accuracy</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>pubmedqa/eval_time_sec</td><td>‚ñà‚ñÜ‚ñÜ‚ñÅ‚ñÖ</td></tr><tr><td>pubmedqa/stderr</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>run_index</td><td>‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pubmedqa/accuracy</td><td>0.776</td></tr><tr><td>pubmedqa/eval_time_sec</td><td>70.70093</td></tr><tr><td>pubmedqa/stderr</td><td>0.01866</td></tr><tr><td>run_index</td><td>5</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">TsinghuaC3I_Llama-3-8B-UltraMedical_pubmedqa_orthopedic_expert_5x</strong> at: <a href='https://wandb.ai/med-moe/med-moe-baseline-evals/runs/hrkxqzhy' target=\"_blank\">https://wandb.ai/med-moe/med-moe-baseline-evals/runs/hrkxqzhy</a><br> View project at: <a href='https://wandb.ai/med-moe/med-moe-baseline-evals' target=\"_blank\">https://wandb.ai/med-moe/med-moe-baseline-evals</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250508_220251-hrkxqzhy/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Benchmark Mental Health Expert\n",
        "import random\n",
        "import json\n",
        "import wandb\n",
        "import subprocess\n",
        "import time\n",
        "import os\n",
        "from datetime import datetime\n",
        "import lm_eval\n",
        "\n",
        "# -----------------------------\n",
        "# üß† Model and Task Config\n",
        "# -----------------------------\n",
        "\n",
        "model_name = \"TsinghuaC3I/Llama-3-8B-UltraMedical\"\n",
        "peft_model_name = \"xj2193/medmoe-mentalhealth-expert\"\n",
        "task_name = \"pubmedqa\"\n",
        "output_base = \"./results\"\n",
        "\n",
        "# -----------------------------\n",
        "# üöÄ Start W&B run\n",
        "# -----------------------------\n",
        "run_name = f\"{model_name.replace('/', '_')}_{task_name}_mentalhealth_expert_5x\"\n",
        "wandb_run = wandb.init(\n",
        "    project=\"med-moe-baseline-evals\",\n",
        "    name=run_name,\n",
        "    config={\n",
        "        \"model\": model_name,\n",
        "        \"task\": task_name,\n",
        "        \"batch_size\": 8,\n",
        "        \"precision\": \"fp16\",\n",
        "        \"eval_method\": \"lm_eval\",\n",
        "        \"repeats\": 5\n",
        "    }\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# üîÅ Run 5x Evaluation Loop\n",
        "# -----------------------------\n",
        "for i in range(5):\n",
        "    print(f\"\\nüîÅ Run {i + 1}/5\")\n",
        "\n",
        "    # Create timestamped output folder\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
        "    day = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    run_output_dir = os.path.join(output_base, f\"run_{i+1}_{timestamp}\")\n",
        "    os.makedirs(run_output_dir, exist_ok=True)\n",
        "\n",
        "    # Define lm_eval command\n",
        "    command = [\n",
        "        \"lm_eval\",\n",
        "        \"--model\", \"hf\",\n",
        "        \"--tasks\", task_name,\n",
        "        \"--model_args\", f\"pretrained={model_name},peft=xj2193/medmoe-mentalhealth-expert,load_in_4bit=True,parallelize=True,device_map=auto,llm_int8_enable_fp32_cpu_offload=True\",\n",
        "        \"--device\", \"cuda:0\",\n",
        "        \"--batch_size\", \"8\",\n",
        "        \"--write_out\",\n",
        "        \"--output_path\", run_output_dir,\n",
        "        \"--trust_remote_code\",\n",
        "        \"--confirm_run_unsafe_code\"\n",
        "    ]\n",
        "\n",
        "    # Start timing\n",
        "    start_time = time.monotonic()\n",
        "    result = subprocess.run(command, capture_output=True, text=True)\n",
        "    elapsed = time.monotonic() - start_time\n",
        "\n",
        "    print(f\"‚úÖ Run {i + 1} completed in {elapsed:.2f} seconds\")\n",
        "    print(\"STDOUT:\\n\", result.stdout)\n",
        "\n",
        "    # -----------------------------\n",
        "    # üìä Find and parse result file\n",
        "    # -----------------------------\n",
        "    result_file = None\n",
        "    for fname in os.listdir(os.path.join(run_output_dir, peft_model_name.replace('/', '__'))):\n",
        "        print(fname)\n",
        "        if fname.startswith(f\"results_{day}\") and fname.endswith(\".json\"):\n",
        "            result_file = os.path.join(run_output_dir, peft_model_name.replace('/', '__'), fname)\n",
        "            with open(result_file, 'r') as f:\n",
        "                result = json.load(f)\n",
        "                acc = result['results'][task_name]['acc,none']\n",
        "                stderr = result['results'][task_name]['acc_stderr,none']\n",
        "\n",
        "                wandb_run.log({f\"{task_name}/eval_time_sec\": elapsed,\n",
        "                              f\"{task_name}/accuracy\": acc,\n",
        "                              f\"{task_name}/stderr\": stderr,\n",
        "                              \"run_index\": i + 1\n",
        "                              })\n",
        "                print(f\"üìà Logged to W&B: acc={acc:.3f}, stderr={stderr:.4f}\")\n",
        "\n",
        "    if result_file is None:\n",
        "        print(f\"‚ùå No eval_results_*.json found in {run_output_dir}\")\n",
        "        continue\n",
        "\n",
        "# -----------------------------\n",
        "# ‚úÖ Finish W&B run\n",
        "# -----------------------------\n",
        "wandb_run.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6yrgZuji8NaM",
        "outputId": "12cddbcd-95e2-485b-cb71-624fe67802af"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250508_220852-mf1ppueu</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/med-moe/med-moe-baseline-evals/runs/mf1ppueu' target=\"_blank\">TsinghuaC3I_Llama-3-8B-UltraMedical_pubmedqa_mentalhealth_expert_5x</a></strong> to <a href='https://wandb.ai/med-moe/med-moe-baseline-evals' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/med-moe/med-moe-baseline-evals' target=\"_blank\">https://wandb.ai/med-moe/med-moe-baseline-evals</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/med-moe/med-moe-baseline-evals/runs/mf1ppueu' target=\"_blank\">https://wandb.ai/med-moe/med-moe-baseline-evals/runs/mf1ppueu</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîÅ Run 1/5\n",
            "‚úÖ Run 1 completed in 71.37 seconds\n",
            "STDOUT:\n",
            " hf (pretrained=TsinghuaC3I/Llama-3-8B-UltraMedical,peft=xj2193/medmoe-mentalhealth-expert,load_in_4bit=True,parallelize=True,device_map=auto,llm_int8_enable_fp32_cpu_offload=True,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "| Tasks  |Version|Filter|n-shot|Metric|   |Value|   |Stderr|\n",
            "|--------|------:|------|-----:|------|---|----:|---|-----:|\n",
            "|pubmedqa|      1|none  |     0|acc   |‚Üë  | 0.77|¬±  |0.0188|\n",
            "\n",
            "\n",
            "results_2025-05-08T22-10-02.585943.json\n",
            "üìà Logged to W&B: acc=0.770, stderr=0.0188\n",
            "\n",
            "üîÅ Run 2/5\n",
            "‚úÖ Run 2 completed in 69.94 seconds\n",
            "STDOUT:\n",
            " hf (pretrained=TsinghuaC3I/Llama-3-8B-UltraMedical,peft=xj2193/medmoe-mentalhealth-expert,load_in_4bit=True,parallelize=True,device_map=auto,llm_int8_enable_fp32_cpu_offload=True,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "| Tasks  |Version|Filter|n-shot|Metric|   |Value|   |Stderr|\n",
            "|--------|------:|------|-----:|------|---|----:|---|-----:|\n",
            "|pubmedqa|      1|none  |     0|acc   |‚Üë  | 0.77|¬±  |0.0188|\n",
            "\n",
            "\n",
            "results_2025-05-08T22-11-12.641609.json\n",
            "üìà Logged to W&B: acc=0.770, stderr=0.0188\n",
            "\n",
            "üîÅ Run 3/5\n",
            "‚úÖ Run 3 completed in 70.47 seconds\n",
            "STDOUT:\n",
            " hf (pretrained=TsinghuaC3I/Llama-3-8B-UltraMedical,peft=xj2193/medmoe-mentalhealth-expert,load_in_4bit=True,parallelize=True,device_map=auto,llm_int8_enable_fp32_cpu_offload=True,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "| Tasks  |Version|Filter|n-shot|Metric|   |Value|   |Stderr|\n",
            "|--------|------:|------|-----:|------|---|----:|---|-----:|\n",
            "|pubmedqa|      1|none  |     0|acc   |‚Üë  | 0.77|¬±  |0.0188|\n",
            "\n",
            "\n",
            "results_2025-05-08T22-12-23.065246.json\n",
            "üìà Logged to W&B: acc=0.770, stderr=0.0188\n",
            "\n",
            "üîÅ Run 4/5\n",
            "‚úÖ Run 4 completed in 70.13 seconds\n",
            "STDOUT:\n",
            " hf (pretrained=TsinghuaC3I/Llama-3-8B-UltraMedical,peft=xj2193/medmoe-mentalhealth-expert,load_in_4bit=True,parallelize=True,device_map=auto,llm_int8_enable_fp32_cpu_offload=True,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "| Tasks  |Version|Filter|n-shot|Metric|   |Value|   |Stderr|\n",
            "|--------|------:|------|-----:|------|---|----:|---|-----:|\n",
            "|pubmedqa|      1|none  |     0|acc   |‚Üë  | 0.77|¬±  |0.0188|\n",
            "\n",
            "\n",
            "results_2025-05-08T22-13-33.202648.json\n",
            "üìà Logged to W&B: acc=0.770, stderr=0.0188\n",
            "\n",
            "üîÅ Run 5/5\n",
            "‚úÖ Run 5 completed in 69.72 seconds\n",
            "STDOUT:\n",
            " hf (pretrained=TsinghuaC3I/Llama-3-8B-UltraMedical,peft=xj2193/medmoe-mentalhealth-expert,load_in_4bit=True,parallelize=True,device_map=auto,llm_int8_enable_fp32_cpu_offload=True,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "| Tasks  |Version|Filter|n-shot|Metric|   |Value|   |Stderr|\n",
            "|--------|------:|------|-----:|------|---|----:|---|-----:|\n",
            "|pubmedqa|      1|none  |     0|acc   |‚Üë  | 0.77|¬±  |0.0188|\n",
            "\n",
            "\n",
            "results_2025-05-08T22-14-42.917097.json\n",
            "üìà Logged to W&B: acc=0.770, stderr=0.0188\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pubmedqa/accuracy</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>pubmedqa/eval_time_sec</td><td>‚ñà‚ñÇ‚ñÑ‚ñÉ‚ñÅ</td></tr><tr><td>pubmedqa/stderr</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>run_index</td><td>‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pubmedqa/accuracy</td><td>0.77</td></tr><tr><td>pubmedqa/eval_time_sec</td><td>69.71517</td></tr><tr><td>pubmedqa/stderr</td><td>0.01884</td></tr><tr><td>run_index</td><td>5</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">TsinghuaC3I_Llama-3-8B-UltraMedical_pubmedqa_mentalhealth_expert_5x</strong> at: <a href='https://wandb.ai/med-moe/med-moe-baseline-evals/runs/mf1ppueu' target=\"_blank\">https://wandb.ai/med-moe/med-moe-baseline-evals/runs/mf1ppueu</a><br> View project at: <a href='https://wandb.ai/med-moe/med-moe-baseline-evals' target=\"_blank\">https://wandb.ai/med-moe/med-moe-baseline-evals</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250508_220852-mf1ppueu/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Benchmark Original Llama-3-8B-UltraMedical\n",
        "import random\n",
        "import json\n",
        "import wandb\n",
        "import subprocess\n",
        "import time\n",
        "import os\n",
        "from datetime import datetime\n",
        "import lm_eval\n",
        "\n",
        "# -----------------------------\n",
        "# üß† Model and Task Config\n",
        "# -----------------------------\n",
        "\n",
        "model_name = \"TsinghuaC3I/Llama-3-8B-UltraMedical\"\n",
        "task_name = \"pubmedqa\"\n",
        "output_base = \"./results\"\n",
        "\n",
        "# -----------------------------\n",
        "# üöÄ Start W&B run\n",
        "# -----------------------------\n",
        "run_name = f\"{model_name.replace('/', '_')}_{task_name}_5x\"\n",
        "wandb_run = wandb.init(\n",
        "    project=\"med-moe-baseline-evals\",\n",
        "    name=run_name,\n",
        "    config={\n",
        "        \"model\": model_name,\n",
        "        \"task\": task_name,\n",
        "        \"batch_size\": 8,\n",
        "        \"precision\": \"fp16\",\n",
        "        \"eval_method\": \"lm_eval\",\n",
        "        \"repeats\": 5\n",
        "    }\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# üîÅ Run 5x Evaluation Loop\n",
        "# -----------------------------\n",
        "for i in range(5):\n",
        "    print(f\"\\nüîÅ Run {i + 1}/5\")\n",
        "\n",
        "    # Create timestamped output folder\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
        "    day = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    run_output_dir = os.path.join(output_base, f\"run_{i+1}_{timestamp}\")\n",
        "    os.makedirs(run_output_dir, exist_ok=True)\n",
        "\n",
        "    # Define lm_eval command\n",
        "    command = [\n",
        "        \"lm_eval\",\n",
        "        \"--model\", \"hf\",\n",
        "        \"--tasks\", task_name,\n",
        "        \"--model_args\", f\"pretrained={model_name},parallelize=True,device_map=auto\",\n",
        "        \"--device\", \"cuda:0\",\n",
        "        \"--batch_size\", \"8\",\n",
        "        \"--write_out\",\n",
        "        \"--output_path\", run_output_dir,\n",
        "        \"--trust_remote_code\",\n",
        "        \"--confirm_run_unsafe_code\"\n",
        "    ]\n",
        "\n",
        "    # Start timing\n",
        "    start_time = time.monotonic()\n",
        "    result = subprocess.run(command, capture_output=True, text=True)\n",
        "    elapsed = time.monotonic() - start_time\n",
        "\n",
        "    print(f\"‚úÖ Run {i + 1} completed in {elapsed:.2f} seconds\")\n",
        "    print(\"STDOUT:\\n\", result.stdout)\n",
        "\n",
        "    # -----------------------------\n",
        "    # üìä Find and parse result file\n",
        "    # -----------------------------\n",
        "    result_file = None\n",
        "    for fname in os.listdir(os.path.join(run_output_dir, model_name.replace('/', '__'))):\n",
        "        print(fname)\n",
        "        if fname.startswith(f\"results_{day}\") and fname.endswith(\".json\"):\n",
        "            result_file = os.path.join(run_output_dir, model_name.replace('/', '__'), fname)\n",
        "            with open(result_file, 'r') as f:\n",
        "                result = json.load(f)\n",
        "                acc = result['results'][task_name]['acc,none']\n",
        "                stderr = result['results'][task_name]['acc_stderr,none']\n",
        "\n",
        "                wandb_run.log({f\"{task_name}/eval_time_sec\": elapsed,\n",
        "                              f\"{task_name}/accuracy\": acc,\n",
        "                              f\"{task_name}/stderr\": stderr,\n",
        "                              \"run_index\": i + 1\n",
        "                              })\n",
        "                print(f\"üìà Logged to W&B: acc={acc:.3f}, stderr={stderr:.4f}\")\n",
        "\n",
        "    if result_file is None:\n",
        "        print(f\"‚ùå No eval_results_*.json found in {run_output_dir}\")\n",
        "        continue\n",
        "\n",
        "# -----------------------------\n",
        "# ‚úÖ Finish W&B run\n",
        "# -----------------------------\n",
        "wandb_run.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c6vDoSsI-Ivc",
        "outputId": "d3bdd5cb-2f75-4f2b-93b1-8541e33dc834"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250508_225001-96tmjtrl</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/med-moe/med-moe-baseline-evals/runs/96tmjtrl' target=\"_blank\">TsinghuaC3I_Llama-3-8B-UltraMedical_pubmedqa_5x</a></strong> to <a href='https://wandb.ai/med-moe/med-moe-baseline-evals' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/med-moe/med-moe-baseline-evals' target=\"_blank\">https://wandb.ai/med-moe/med-moe-baseline-evals</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/med-moe/med-moe-baseline-evals/runs/96tmjtrl' target=\"_blank\">https://wandb.ai/med-moe/med-moe-baseline-evals/runs/96tmjtrl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîÅ Run 1/5\n",
            "‚úÖ Run 1 completed in 47.71 seconds\n",
            "STDOUT:\n",
            " hf (pretrained=TsinghuaC3I/Llama-3-8B-UltraMedical,parallelize=True,device_map=auto,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "| Tasks  |Version|Filter|n-shot|Metric|   |Value|   |Stderr|\n",
            "|--------|------:|------|-----:|------|---|----:|---|-----:|\n",
            "|pubmedqa|      1|none  |     0|acc   |‚Üë  | 0.76|¬±  |0.0191|\n",
            "\n",
            "\n",
            "results_2025-05-08T22-50-48.255789.json\n",
            "üìà Logged to W&B: acc=0.760, stderr=0.0191\n",
            "\n",
            "üîÅ Run 2/5\n",
            "‚úÖ Run 2 completed in 47.81 seconds\n",
            "STDOUT:\n",
            " hf (pretrained=TsinghuaC3I/Llama-3-8B-UltraMedical,parallelize=True,device_map=auto,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "| Tasks  |Version|Filter|n-shot|Metric|   |Value|   |Stderr|\n",
            "|--------|------:|------|-----:|------|---|----:|---|-----:|\n",
            "|pubmedqa|      1|none  |     0|acc   |‚Üë  | 0.76|¬±  |0.0191|\n",
            "\n",
            "\n",
            "results_2025-05-08T22-51-36.046583.json\n",
            "üìà Logged to W&B: acc=0.760, stderr=0.0191\n",
            "\n",
            "üîÅ Run 3/5\n",
            "‚úÖ Run 3 completed in 47.48 seconds\n",
            "STDOUT:\n",
            " hf (pretrained=TsinghuaC3I/Llama-3-8B-UltraMedical,parallelize=True,device_map=auto,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "| Tasks  |Version|Filter|n-shot|Metric|   |Value|   |Stderr|\n",
            "|--------|------:|------|-----:|------|---|----:|---|-----:|\n",
            "|pubmedqa|      1|none  |     0|acc   |‚Üë  | 0.76|¬±  |0.0191|\n",
            "\n",
            "\n",
            "results_2025-05-08T22-52-23.541148.json\n",
            "üìà Logged to W&B: acc=0.760, stderr=0.0191\n",
            "\n",
            "üîÅ Run 4/5\n",
            "‚úÖ Run 4 completed in 47.36 seconds\n",
            "STDOUT:\n",
            " hf (pretrained=TsinghuaC3I/Llama-3-8B-UltraMedical,parallelize=True,device_map=auto,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "| Tasks  |Version|Filter|n-shot|Metric|   |Value|   |Stderr|\n",
            "|--------|------:|------|-----:|------|---|----:|---|-----:|\n",
            "|pubmedqa|      1|none  |     0|acc   |‚Üë  | 0.76|¬±  |0.0191|\n",
            "\n",
            "\n",
            "results_2025-05-08T22-53-10.910418.json\n",
            "üìà Logged to W&B: acc=0.760, stderr=0.0191\n",
            "\n",
            "üîÅ Run 5/5\n",
            "‚úÖ Run 5 completed in 47.48 seconds\n",
            "STDOUT:\n",
            " hf (pretrained=TsinghuaC3I/Llama-3-8B-UltraMedical,parallelize=True,device_map=auto,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "| Tasks  |Version|Filter|n-shot|Metric|   |Value|   |Stderr|\n",
            "|--------|------:|------|-----:|------|---|----:|---|-----:|\n",
            "|pubmedqa|      1|none  |     0|acc   |‚Üë  | 0.76|¬±  |0.0191|\n",
            "\n",
            "\n",
            "results_2025-05-08T22-53-58.365109.json\n",
            "üìà Logged to W&B: acc=0.760, stderr=0.0191\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pubmedqa/accuracy</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>pubmedqa/eval_time_sec</td><td>‚ñÜ‚ñà‚ñÉ‚ñÅ‚ñÉ</td></tr><tr><td>pubmedqa/stderr</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>run_index</td><td>‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pubmedqa/accuracy</td><td>0.76</td></tr><tr><td>pubmedqa/eval_time_sec</td><td>47.48327</td></tr><tr><td>pubmedqa/stderr</td><td>0.01912</td></tr><tr><td>run_index</td><td>5</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">TsinghuaC3I_Llama-3-8B-UltraMedical_pubmedqa_5x</strong> at: <a href='https://wandb.ai/med-moe/med-moe-baseline-evals/runs/96tmjtrl' target=\"_blank\">https://wandb.ai/med-moe/med-moe-baseline-evals/runs/96tmjtrl</a><br> View project at: <a href='https://wandb.ai/med-moe/med-moe-baseline-evals' target=\"_blank\">https://wandb.ai/med-moe/med-moe-baseline-evals</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250508_225001-96tmjtrl/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}